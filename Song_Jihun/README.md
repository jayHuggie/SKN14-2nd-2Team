# 진행과정 정리 및 결론

## 1. 선정한 모델의 순수 성능과 하이퍼파라미터를 조정했을 때의 성능을 우선 비교해봄
- 선정한 모델
  - RandomForestClassifier
  - XGBoost
> 결과 : 두 모델 모두 평균 86% 의 정확도를 보임<br/>
> => Next step : 모델의 하이퍼파라미터 조정해보기

---------------------------------------------------------------------------

## 2. 간단한 데이터 전처리 및 RandomForestClassifier 의 하이퍼파라미터들을 조정해가면서 성능 개선 시도
- 스케일링 방법 변경
  - StandardScaler
  - MinMaxScaler
- 파라미터 목록
  - max_depth
  - criterion
  - min_samples_leaf
  - n_estimators
  - max_features
> 결과 : n_estimators 에서 미미한 개선을 보였으나, 큰 효과가 없음.<br/>
> Next step : 하이퍼파라미터의 조합으로 성능개선해보기

---------------------------------------------------------------------------

## 3. 최적의 하이퍼파라미터 조합을 찾기 위해 GridSearchCV 로 최적의 조합검색 시도
- 시도한 하이퍼파라미터

  | Parameter         | Elements                        |
  |:------------------|:--------------------------------|
  | n_estimators      | [100, 300, 500]                 |
  | max_depth         | [5, 8, 10, None]                |
  | min_samples_split | [10, 30, 50]                    |
  | max_features      | ['sqrt', 'log2', None]          |
  | criterion         | ["gini", "entropy", "log_loss"] |
  | min_samples_leaf  | [10, 30, 50, 80]                |

> 결과 : 성능개선 효과가 없음<br/>
> Next step : RandomForest 말고 다른 모델은 어떤지 확인해보기

---------------------------------------------------------------------------

## 4. XGBoost 에서는 성능이 어떤지 확인

> 결과 : 큰 차이가 없음.<br/>
> Next step : 모델이 아닌 다른 문제가 아닌지 확인해보기

---------------------------------------------------------------------------

## 5. 모델이 아닌 데이터셋에서 해결책을 모색하기 시작함( Feature Drop )
- XGBoost 에서 feature_importances 를 확인해본 결과 중요도가 떨어지는 컬럼들이 다수 존재함.
  - 해당 컬럼들을 Noise 로 규정하고, 학습/검증 과정에서 배제.
  - 배제한 컬럼
    - "CreditScore"
    - "EstimatedSalary"
    - "Tenure"
    - "HasCrCard"

> 결과 : 의미있는 성능변화가 없음<br/>
> Next step : 중요도가 낮은 특성 말고, 높은 특성으로 확인해보기

---------------------------------------------------------------------------

## 6. 반대로, 중요도가 높은 컬럼들만 모아서 성능개선 시도
- XGBoost 의 feature_importances 에서 중요도가 높았던 특성들만으로 성능개선 시도
- 사용한 컬럼
  - "IsActiveMember"
  - "NumOfProducts"
  - "Age"
  - "Balance"

> 결과 : 의미있는 성능변화가 없음<br/>
> Next step : 중요도보다 더 영향이 큰, 다른 원인 파악하기

---------------------------------------------------------------------------

## 7. 데이터의 불균형을 해소하기 위해 양성/음성의 개수를 맞춤
- 4:1 비율의 음성/양성 데이터를 양성데이터 개수로 1:1 이 되도록 음성데이터를 랜덤추출.
- 추출한 데이터로 학습/검증 데이터셋을 구성하여 모델 학습 및 검증 진행

> 결과 : 성능이 오히려 더 악화됨<br/>
> Next step : 데이터량을 줄이지 않은 상태로 성능개선 방법 찾아보기

---------------------------------------------------------------------------

## 8. 모델 변경, Feature engineering, Threshold 조정으로 개선시도
- 모델을 HistGradientBoostingClassifier 로 변경하고, 임계값은 변경하지 않음.
- 데이터의 불균형을 개선하여 학습/검증 진행
  - 음성데이터의 $2/3$ 와 양성데이터 전체를 묶어서 학습/검증셋을 만들고
  - 음성데이터의 나머지 $1/3$ 을 검증셋과 합친다.
  - 모델을 학습셋으로 학습시키고, 검증셋으로 성능평가 진행.
- 그 후 임계값도 조정해서 성능비교.

> 결과 : 임계값 조정 전에는 정확도가 2%p 개선되었지만, 임계값 조정 후에는 오히려 하락함.
> Next step : 데이터셋 평가 및 추가로 성능에 영향을 주는 요소 찾아보기

---------------------------------------------------------------------------

## 9. 추후 진행방향
- 추가 데이터 확보 없이 성능개선을 어떻게 할 수 있을지 고민 필요
- 데이터셋에 추가조작없이 기본적인 전처리만으로 성능을 어떻게 개선할지 고민 필요.

---------------------------------------------------------------------------
